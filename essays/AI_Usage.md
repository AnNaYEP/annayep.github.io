---
layout: essay
type: essay
image: ..\img\AI_Usage\AVATAR_SQUARE_2D_DARK.png
title: "Smart Questions? Why?"
#[![Alt text](image-url)](target-url)
date: 2025-10-16
published: true
labels:
  - Cursor
  - GitHub Copilot
  - Microsoft Copilot
  - AI
  - LLM
summary: "Reflecting on Typescript."
---

![CursorLockup ](..\img\AI_Usage\LOCKUP_HORIZONTAL_2D_LIGHT.svg)

# AI Introducton
The role of AI usage in education pertaining to Software Engineering is an interesting one. I could not imagine being able to just press `Tab` and have comments or blocks of template code just written out for me. Because Software Engineering is such a broad field with close ties in Machine Learning development, it was definitely a different landscape than it was just 3 years ago. Growing up programming without AI, I feel it isn’t a crutch to me as it could have been if it were introduced to me earlier. AI is just another option for assistance, like a consultant. It _has_ knowledge, but it is up to the person using it to either go with or against its suggestions.
I have used Google Gemini to look for sources after it gives me a summary of websites that could have what I am looking for; Microsoft Copilot for general knowledge, and when I do not feel like waiting for a browser to re-open all my tabs; Google Lens for translations and bug/plant identification; Github Copilot for autocomplete and double-checking programs; and Cursor Agents (GPT 4.1 and Grok as they are the only free models I could use) to look through my project directory for problematic code that might affect the file I am working on.


# Coursework Usage
For WODs, I originally avoided AI for other reasons, but I did start utilizing it more for programming when I realized that it has become sort of the norm. One of our assignments required us to learn about functional programming, and I did my best to read the documentation and implementation of what we were supposed to learn. I nearly got there, but got only ten percent of the grade due to the code not working the right way. Learning that a large percentage of people use AI around the middle of the semester threw me for a loop. Reading documentation just makes sense to me, but AI can digest everything in seconds and spit out what it thinks you need. Being in a position where I would have to “get with the times” felt weird, but if it’s helping others, I decided to take all the help I could get. There were other people who would’ve been just as stuck as I, but because they had little to no stigma towards AI, they were able to stay on track, which I struggled with in class and in school in general.

Early on, at most, I would use Copilot’s autocomplete for comments and Google’s Gemini search results. This was true for In-class WODs too. For the WODs before the final project, however, I realized I could have been using AI to do all the tedious work like quickly changing my code for me while I was left to think. The only instance of using AI in relation to my essays was actually just seconds ago, where I realized my images on some essays were linked wrong. For actual writing, however, all text is my own. I wouldn’t want AI to write  my thoughts out for me, cause it just wouldn’t be me.

For the final project, whenever I encountered an error I could not solve on my own, I asked cursor’s agent for assistance. It “helped” find issues that could be found within code, but I personally found that just reading up on documentation and telling it what I knew and suspect what might be wrong was the best way to go about it, personally. This meant searching forums and other sites for assistance (with things like PostgreSQL compatibility with ARM64 laptops), as I could not expect a programming model to know hardware specifics.

# Technical and Social Usage
For learning a concept/tutorial, at most I would see what Google search’s AI would have to say, then find a source that mentioned what was brought up. I have read too many goofy personal anecdotes about AI hallucinating, and I would hate to be a victim of that.
For answering a question in class or on Discord, we already have the ics 314 website. Using AI to answer a question one-on-one just feels disengenious to me, personally. While I do see the use in answering questions everyone has been searching for on a team, I didn’t feel the need to do so, as the professors made everything that we needed to pass available and categorized. No AI was used by me for asking or answering a smart-question. This was either because other people would have an answer before I do, or I am just as stumped as they are.

# Writing Code
For coding examples, I tried to use it to help me with databases, but I got nowhere. I asked GitHub Copilot, “Yo, my database machine broke,” but got an answer I had already tried. I was personally left even more confused as to how I would proceed until I looked at the 314 website. It was a way easier experience to also just ask other people because we’re all in the same boat.
Any provided code from the class I felt was pretty self-explanatory, but Cursor or Github Copilot would sometimes explain their suggested changes when I would ask if my code was written correctly, which made me feel more confident in its utilization in the workforce. An example prompt would be "I’m getting this error, but when I tried ‘x’ to fix it, it gave me ‘y’. This would sometimes yield useful results, but I always benefited more from understanding the message first, then seeing if an AI would either try to confirm or correct my course of actions.

For writing code, I did use Cursor in the second half of the semester to assist with programming, but only if I knew what it was actually writing. Having it rewrite error-filled portions of code that had errors sped up development. For documentation, GitHub CoPilot would occasionally fill out comments as soon as I typed the appropriate characters like `#` or `//`. I felt it was incredibly useful, as it had no effect on code functionality and yet still improved any project.
AI was very useful for quality assurance, as I often ran into many issues into the semester with an arm64 laptop. I eventually swapped to my old Windows laptop, yielding much less issues. While documentation does exist and I find it very useful, I could not imagine myself looking through every possible related package to see what is causing me issues. I’d rather just `npm uninstall` into `npm i` and hope for the best. Node packages just wouldn’t install correctly, and I would always be spending more time fixing my local development than actual developing. For QA, I would say AI does what we hoped it would do a couple of years back. When I would ask if my code was written correctly, it usually gave a suggestion and mentioned improperly placed blocks of my own code.


# Impact on Learning and Understanding:
I have mainly been using it to save me keystrokes and minutes here and there on the keyboard. I do not feel like it has affected my comprehension, as I still do not vibe with the code it generates if I do not fully understand what it wrote. I feel I learned far more than what I could have, and have gained more in skill development, as it would always point me towards issues and solutions by using documentation and pre-existing code to get me to where I usually need to be. AI tech has largely enhanced my understanding of software engineering concepts, but it also feels like it may be a challenge in the future. I say this because one day I might have to work on fixing code that some LLM generated, and if it has any errors, another LLM might pass it off as passing because it was made by a similar LLM model.

# Practical Applications:
AI has many practical applications. One instance could be in scheduling, and could account for factors we might occasionally oversee. Some factors could be travel times, foreign holidays during travel, or weather patterns. It can also be used for assisting others. While AI can be helpful, it will still be up to humans to create and implement new ideas.

# Challenges and Opportunities:
One limitation I feel is how much students are willing to learn. Telling an AI to fix code is one thing, but actually understanding how program execution works is a different thing. An AI could explain and provide, but it may only provide what it thinks is correct. It would be up to the user to elaborate more on whether or not they could do something different instead. I found this helped me a lot in getting used to AI. For example, Cursor would suggest I implement a function this way, but it doesn’t work. By understanding more about how the program and actual GUI worked and functioned, I was able to figure out that the code was correct, just in the wrong spot, giving me errors.

# Comparative Analysis:
An AI and a professor knows how programs work, but only a human professor could actually have been in the same place as their students when stuck on an issue. The human element and encouragement have more value. A student’s knowledge retention and practical skill development increase with an authority figure present. AI-enhanced approaches can be just as efficient as traditional methods, so why not use them everywhere? That's because an LLM only knows things. A professor in the same field as you has walked in the same, if not similar, shoes as their peers. This allows for dynamic problem solving and teaching in a learning environment with multiple variables. AI-enhanced teaching can assist with teaching, but it still builds off on whatever information we feed it, correct or not.

# Future Considerations:
Project-based exams are the future due to the possibility of using AI to cheat logically being on the rise. Unless people are willing to spend more time on proctoring exams, it would be less cost-effective in terms of both money and time spent only testing people on theory alone, instead of both theory and practice. Ethics is huge, as the data that people pass onto LLMs may be used, violating a [university's security standards](https://www.hawaii.edu/infosec/minimum-standards/). It may feel harmless to pass grading work onto a machine, but if propriatery or protected software being developed is ever examined by an AI assistant, it could use said data to assist an unrelated party.
An advancement I do see is the decrease in what basically are knowledge checks. It is good to be tested on knowledge, as it would be bad to hire someone clueless as to how software works. Sometimes, however, I feel it has been used as a benchmark of how much one can remember, as they forget what they just learned, only to make space for the next knowledge check.

# Conclusion:
In conclusion, because AI isn’t going anywhere, I feel like it would be good to help students get started with getting familiar with AI. I do not mean this in a way where we would need to use AI to pass college, but in a way that would help students get used to using other sources for help.
I feel a survey with anonymized data published for new classes on the % of students who used AI (maybe even throughout the semester) would set expectations and help encourage people to get used to a tool that is only going to accelerate everyone’s development and progress, not just in ICS, but with life in general. I think it would be neat to have some WODs adapted to also teach about AI ethics, or just education on how AI works in general. It would be able to keep the practical aspect of WODs while also teaching about a still-emerging technology.